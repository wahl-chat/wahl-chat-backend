{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "def scrape_voting_behavior(vote_id: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Scrapes voting behavior data from the Bundestag website for a specific vote ID,\n",
    "    capturing date, title, descriptive text, overall results, and results by party.\n",
    "    \"\"\"\n",
    "    url = (\n",
    "        f\"https://www.bundestag.de/parlament/plenum/abstimmung/abstimmung?id={vote_id}\"\n",
    "    )\n",
    "\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Parse date\n",
    "    date_span = soup.select_one(\"span.bt-date\")\n",
    "    date = date_span.get_text(strip=True) if date_span else None\n",
    "\n",
    "    # Parse title\n",
    "    title_h1 = soup.select_one(\"h1.bt-artikel__title\")\n",
    "    title = title_h1.get_text(strip=True) if title_h1 else None\n",
    "\n",
    "    # Parse subtitle\n",
    "    subtitle_p = soup.select_one(\"article.bt-artikel p\")\n",
    "    subtitle = subtitle_p.get_text(strip=True) if subtitle_p else None\n",
    "\n",
    "    # parse detail text\n",
    "    article_content_div = soup.select_one(\"article.bt-artikel .bt-standard-content\")\n",
    "    if article_content_div:\n",
    "        paragraphs = article_content_div.find_all(\"p\")\n",
    "        detail_text = \"\\n\\n\".join(\n",
    "            p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)\n",
    "        )\n",
    "    else:\n",
    "        detail_text = \"\"\n",
    "\n",
    "    # Overall results\n",
    "    overall = {}\n",
    "    overall_chart = soup.select_one(\".bt-bar-chart .bt-chart-legend\")\n",
    "    if overall_chart:\n",
    "        for li in overall_chart.find_all(\"li\"):\n",
    "            label_class = li.get(\"class\", [])\n",
    "            count = li.find(\"span\").get_text(strip=True)\n",
    "\n",
    "            if \"bt-legend-ja\" in label_class:\n",
    "                overall[\"yes\"] = count\n",
    "            elif \"bt-legend-nein\" in label_class:\n",
    "                overall[\"no\"] = count\n",
    "            elif \"bt-legend-enthalten\" in label_class:\n",
    "                overall[\"abstain\"] = count\n",
    "            elif \"bt-legend-na\" in label_class:\n",
    "                overall[\"not_voted\"] = count\n",
    "\n",
    "    # Parse number of members\n",
    "    members_span = soup.select_one(\".bt-bar-chart .bt-teaser-text-chart h3\")\n",
    "    if members_span:\n",
    "        text = members_span.get_text(strip=True)\n",
    "        maybe_nums = [token for token in text.split() if token.isdigit()]\n",
    "        if maybe_nums:\n",
    "            overall[\"members\"] = maybe_nums[0]\n",
    "\n",
    "    # Result by party\n",
    "    by_party = []\n",
    "    party_blocks = soup.select(\".bt-teaser-chart-solo\")\n",
    "    for pb in party_blocks:\n",
    "        party_name = pb.get(\"data-value\", \"\").strip()\n",
    "        h4 = pb.select_one(\"h4.bt-chart-fraktion\")\n",
    "        party_members = None\n",
    "        if h4:\n",
    "            span = h4.select_one(\"span\")\n",
    "            if span:\n",
    "                pm_text = span.get_text(strip=True)\n",
    "                pm_tokens = pm_text.split()\n",
    "                if pm_tokens and pm_tokens[0].isdigit():\n",
    "                    party_members = pm_tokens[0]\n",
    "\n",
    "        # Now parse the yes/no/abstain/not_voted results\n",
    "        results_dict = {}\n",
    "        ul = pb.select_one(\".bt-chart-legend\")\n",
    "        if ul:\n",
    "            for li in ul.find_all(\"li\"):\n",
    "                li_text = li.get_text(strip=True)\n",
    "                li_parts = li_text.split()\n",
    "                if len(li_parts) > 1:\n",
    "                    count = li_parts[0]\n",
    "\n",
    "                    label = li_parts[1].lower()\n",
    "\n",
    "                    if \"ja\" in label:\n",
    "                        results_dict[\"yes\"] = count\n",
    "                    elif \"nein\" in label:\n",
    "                        results_dict[\"no\"] = count\n",
    "                    elif \"enthalten\" in label:\n",
    "                        results_dict[\"abstain\"] = count\n",
    "                    elif \"nicht\" in label:  # \"Nicht abg.\"\n",
    "                        results_dict[\"not_voted\"] = count\n",
    "\n",
    "        by_party.append({\"party\": party_name, \"members\": party_members, **results_dict})\n",
    "\n",
    "    # Parse links\n",
    "    link_list = soup.select_one(\".bt-linkliste\")\n",
    "    if link_list:\n",
    "        links = []\n",
    "        for li in link_list.find_all(\"li\"):\n",
    "            a = li.select_one(\"a\")\n",
    "            if a:\n",
    "                href = a.get(\"href\", \"\")\n",
    "                link_title = a.get(\"title\", \"\")\n",
    "                links.append({\"url\": href, \"title\": link_title})\n",
    "\n",
    "    # Build final dict\n",
    "    return {\n",
    "        \"id\": vote_id,\n",
    "        \"url\": url,\n",
    "        \"date\": date,\n",
    "        \"title\": title,\n",
    "        \"subtitle\": subtitle,\n",
    "        \"detail_text\": detail_text,\n",
    "        \"links\": links,\n",
    "        \"voting_results\": {\"overall\": overall, \"by_party\": by_party},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterates from 939 down to 1 and scrapes each vote. Writes the results to a file.\n",
    "import os\n",
    "from time import sleep\n",
    "\n",
    "if not os.path.exists(\"../votes\"):\n",
    "    os.makedirs(\"../votes\")\n",
    "\n",
    "for vote_id in range(939, 1, -1):\n",
    "    data = scrape_voting_behavior(str(vote_id))\n",
    "    with open(f\"../votes/vote_{vote_id}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all the votes from 377 to 939 and open them\n",
    "chars = []\n",
    "longest = 0\n",
    "longest_id = 0\n",
    "\n",
    "for vote_id in range(377, 940):\n",
    "    with open(f\"../votes/vote_{vote_id}.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    chars.append(len(data[\"detail_text\"]))\n",
    "\n",
    "    if len(data[\"detail_text\"]) > longest:\n",
    "        longest = len(data[\"detail_text\"])\n",
    "        longest_id = vote_id\n",
    "\n",
    "print(f\"Average number of characters per vote: {sum(chars) / len(chars)}\")\n",
    "print(f\"Longest vote: {max(chars)}\")\n",
    "print(f\"Shortest vote: {min(chars)}\")\n",
    "\n",
    "with open(f\"../votes/vote_{longest_id}.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "print(data[\"detail_text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wahl-chat-backend-qKsRGN7D-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
